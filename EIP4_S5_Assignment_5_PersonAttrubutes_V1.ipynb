{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP4-S5-Assignment 5 -PersonAttrubutes.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anilbhatt1/CNN-EIP4-S5/blob/master/EIP4_S5_Assignment_5_PersonAttrubutes_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip -q \"/content/gdrive/My Drive/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import time, math\n",
        "from tqdm import tqdm_notebook as tqdm  #This is for progress bar\n",
        "import matplotlib.pyplot as plt\n",
        "#from random_eraser import get_random_eraser\n",
        "\n",
        "import tensorflow as tf\n",
        "#from tensorflow.keras import Sequence\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
        "], axis = 1)\n",
        "\n",
        "one_hot_df.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll94zTv6w5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from tensorflow.python.keras.utils.data_utils import Sequence\n",
        "\n",
        "# Label columns per attribute\n",
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
        "\n",
        "class PersonalDataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Ground truth data generator\"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self, df, batch_size=32, shuffle=True):\n",
        "        self.df = df\n",
        "        self.batch_size=batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "       # self.df.shape[0] = shape\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"fetch batched images and targets\"\"\"\n",
        "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        items = self.df.iloc[batch_slice]\n",
        "        image = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])\n",
        "        target = {\n",
        "            \"gender_output\": items[_gender_cols_].values,\n",
        "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
        "            \"age_output\": items[_age_cols_].values,\n",
        "            \"weight_output\": items[_weight_cols_].values,\n",
        "            \"bag_output\": items[_carryingbag_cols_].values,\n",
        "            \"pose_output\": items[_bodypose_cols_].values,\n",
        "            \"footwear_output\": items[_footwear_cols_].values,\n",
        "            \"emotion_output\": items[_emotion_cols_].values,\n",
        "        }\n",
        "        return image, target\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        if self.shuffle == True:\n",
        "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6hYowvtJ4B8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5m15DLyF2ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_gen = PersonalDataGenerator(train_df, batch_size=32)\n",
        "valid_gen = PersonalDataGenerator(val_df, batch_size=64, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_gen))\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
        "num_units"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfqGoDu0PXiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(num_units)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03W8Pagg_Ppp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv_bottleNeck(tf.keras.Model):\n",
        "    expansion = 4\n",
        "    def __init__(self,input_channels,channels,stride=1,dim_change=None):\n",
        "        super(Conv_bottleNeck,self).__init__()\n",
        "        \n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=channels,kernel_size=1,strides=1)  # 1x1xdesired channels\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization() # Batch-Normalization\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=channels,kernel_size=3,strides=stride,padding='same') # 3x3xdesired channels\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization() # Batch-Norm\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters=channels*self.expansion,kernel_size=1)  # 1x1x4*desired channels that were at begining\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization() # Batch-norm\n",
        "        self.dim_change = dim_change # Will get this dim_change from Resnet class\n",
        "    \n",
        "    def forward(self,x):    # Main logic \n",
        "        res = x\n",
        "        \n",
        "        output = tf.nn.relu(self.bn1(self.conv1(x)))  # 1x1xinput size -> BN -> Relu\n",
        "        output = tf.nn.relu(self.bn2(self.conv2(output)))  # 3x3xinput size -> BN -> Relu\n",
        "        output = self.bn3(self.conv3(output))  # 3x3x4*input size -> BN\n",
        "\n",
        "        if self.dim_change is not None:\n",
        "            res = self.dim_change(res)   # Applying dim_change we get from ResNet class to the residual block if dimension expansion is there\n",
        "        \n",
        "        output += res             # Adding residual block with skip network\n",
        "        output = tf.nn.relu(output)   # Applying relu on combined output\n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT2gplBdf3wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Resnet_50(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,block_type,num_layers,classes=8):\n",
        "        super(Resnet_50,self).__init__()\n",
        "        \n",
        "        self.inp_channels=64\n",
        "        self.conv1_res = tf.keras.layers.Conv2D(filters=self.inp_channels, kernel_size=7, strides=2,padding='same',use_bias=False)\n",
        "        self.bn1_res = tf.keras.layers.BatchNormalization() # There needs to have a Relu after this\n",
        "        self.pool2D_res = tf.keras.layers.MaxPooling2D()\n",
        "        self.layer1 = self._layer(block_type,64,num_layers[0],stride=1)\n",
        "        self.layer2 = self._layer(block_type,128,num_layers[1],stride=2) \n",
        "        self.layer3 = self._layer(block_type,256,num_layers[2],stride=2) \n",
        "        self.layer4 = self._layer(block_type,512,num_layers[3],stride=2)\n",
        "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.fully_connected = tf.keras.layers.Dense(8, kernel_initializer='he_normal', use_bias=False)\n",
        "\n",
        "    def _layer(self,block_type,channels,numb_layers,stride=1):\n",
        "         dim_change = None\n",
        "         if stride!=1 or channels != self.inp_channels*block_type.expansion:\n",
        "             dim_change = tf.keras.Sequential(tf.keras.layers.Conv2D(filters=channels*block_type.expansion,kernel_size=1,strides=stride),\n",
        "                                             tf.keras.layers.BatchNormalization())\n",
        "         netLayers =[]\n",
        "         netLayers.append(block_type(self.inp_channels,channels,stride=stride,dim_change=dim_change))\n",
        "         self.inp_channels = channels * block_type.expansion\n",
        "         for i in range(1,numb_layers):\n",
        "           netLayers.append(block_type(self.inp_channels,channels))\n",
        "           self.inp_channels = channels * block_type.expansion\n",
        "         return tf.keras.Sequential(netLayers)\n",
        "\n",
        "    def forward(self,x):    # Main logic\n",
        "      x = tf.nn.relu(self.bn1_res(self.conv1_res(x)))  # 7x7 -> BN -> Relu\n",
        "      x = self.pool2D_res(x)   # Maxpooling\n",
        "      x = self.layer1(x)       # Logic to build layer 1, for Resnet 50 there will be 3 blocks\n",
        "      x = self.layer2(x)       # Building layer 2, there will be 4 blocks\n",
        "      x = self.layer3(x)       # Building layer 3, there will be 6 blocks\n",
        "      x = self.layer4(x)       # Building layer 4, there will be 3 blocks\n",
        "      x = self.avgpool(x)      # Global Average pooling\n",
        "      x = self.fully_connected(x)  # Fully connected"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JgNVs68yxiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Resnet_50(Conv_bottleNeck,[3,4,6,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfPG9C2eA1zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# losses = {\n",
        "# \t\"gender_output\": \"binary_crossentropy\",\n",
        "# \t\"image_quality_output\": \"categorical_crossentropy\",\n",
        "# \t\"age_output\": \"categorical_crossentropy\",\n",
        "# \t\"weight_output\": \"categorical_crossentropy\",\n",
        "\n",
        "# }\n",
        "# loss_weights = {\"gender_output\": 1.0, \"image_quality_output\": 1.0, \"age_output\": 1.0}\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw2ZRIQ7BW-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxv41EyNmN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=train_gen,\n",
        "    validation_data=valid_gen,\n",
        "    use_multiprocessing=True,\n",
        "    workers=6, \n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5EMwEga4lFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#datagen = ImageDataGenerator(zoom_range=0.0, \n",
        "                             horizontal_flip=False)\n",
        "# train the model\n",
        "#start = time.time()\n",
        "\n",
        "#model_info = model.fit_generator(datagen.flow(train_gen, batch_size = 128),\n",
        "#                                 samples_per_epoch = train_gen.shape[0], nb_epoch = 10, \n",
        "#                                 validation_data = (val_gen), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI1hJb4qM6OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}